"""
src/multi_agent.py
Self-RAG + Web Search: æœ¬åœ°æœä¸åˆ° -> è‡ªåŠ¨è”ç½‘æœ -> æ™ºèƒ½å›ç­”
"""
import sys
import os
import uuid
from typing import Annotated, TypedDict, List
from langgraph.graph import StateGraph, START, END
from langgraph.graph.message import add_messages
from langgraph.checkpoint.sqlite import SqliteSaver
import sqlite3
from langchain_core.messages import AIMessage, HumanMessage

# å¯¼å…¥åŒçº§æ¨¡å—
sys.path.append(os.path.dirname(os.path.abspath(__file__)))
from tools import medical_tools_list

# ğŸ”¥ å…³é”®ä¿®æ”¹ï¼šä»å¼•æ“å¯¼å…¥ web_search_tool
# å¦‚æœè¿™é‡ŒæŠ¥é”™ï¼Œè¯·æ£€æŸ¥ src/medical_engine.py æ˜¯å¦å·²ç»æ·»åŠ äº† TavilySearchResults
try:
    from medical_engine import llm, llm_with_tools, search_knowledge_base, vectorstore, web_search_tool
except ImportError:
    print("âŒ é”™è¯¯: æ— æ³•ä» medical_engine å¯¼å…¥ web_search_toolã€‚è¯·ç¡®ä¿ä½ å·²æ›´æ–° medical_engine.py å¹¶å®‰è£…äº† tavily-pythonã€‚")
    sys.exit(1)

# --- 1. å®šä¹‰çŠ¶æ€ ---
class MultiAgentState(TypedDict):
    messages: Annotated[list, add_messages]
    need_tool: bool
    need_rag: bool
    need_lifestyle: bool
    
    tool_output: str
    rag_output: str
    lifestyle_output: str
    final_answer: str
    
    documents: List[str]
    loop_step: int
    # ğŸ”¥ æ–°å¢æ ‡å¿—ï¼šæ˜¯å¦ä½¿ç”¨äº†ç½‘ç»œæœç´¢
    used_web_search: bool 

# --- 2. è¾…åŠ©å‡½æ•° ---

def grade_documents(question: str, docs: List[str]) -> str:
    """é˜…å·è€å¸ˆï¼šåˆ¤æ–­æ–‡æ¡£æ˜¯å¦ç›¸å…³"""
    print("  âš–ï¸ [è¯„åˆ¤] æ­£åœ¨è¯„ä¼°æ–‡æ¡£è´¨é‡...")
    if not docs: return "no"
    
    # ç®€å•æ‹¼æ¥å‰ä¸¤ä¸ªæ–‡æ¡£è¿›è¡Œè¯„ä¼°
    context = "\n".join(docs[:2]) 
    prompt = f"""
    ä½ æ˜¯ä¸€åè¯„åˆ†å‘˜ã€‚è¯·è¯„ä¼°æ–‡æ¡£æ˜¯å¦åŒ…å«å›ç­”é—®é¢˜çš„ä¿¡æ¯ã€‚
    
    æ–‡æ¡£ç‰‡æ®µï¼š
    {context}
    
    ç”¨æˆ·é—®é¢˜ï¼š
    {question}
    
    å¦‚æœæ–‡æ¡£èƒ½æä¾›å“ªæ€•ä¸€ç‚¹ç‚¹çº¿ç´¢ï¼Œéƒ½å›ç­” 'yes'ã€‚
    åªæœ‰å®Œå…¨ä¸ç›¸å…³æ‰å›ç­” 'no'ã€‚
    åªå›ç­”ï¼šyes æˆ– no
    """
    score = llm.invoke(prompt).content.strip().lower()
    print(f"    ğŸ‘‰ è¯„åˆ†: {score}")
    return "yes" if "yes" in score else "no"

def rewrite_query(question: str) -> str:
    """æ”¹é¢˜ä¸“å®¶ï¼šé‡å†™æœç´¢è¯"""
    print(f"  ğŸ”„ [ä¼˜åŒ–] æ­£åœ¨é‡å†™æœç´¢è¯...")
    prompt = f"""
    åŸé—®é¢˜æ£€ç´¢å¤±è´¥ï¼Œè¯·é‡å†™ä¸€ä¸ªæ›´å¥½çš„æœç´¢æŸ¥è¯¢è¯ã€‚
    åŸé—®é¢˜ï¼š{question}
    åªè¾“å‡ºæ–°çš„æŸ¥è¯¢è¯ã€‚
    """
    new_query = llm.invoke(prompt).content.strip()
    print(f"    ğŸ‘‰ æ–°è¯: {new_query}")
    return new_query

# --- 3. èŠ‚ç‚¹å®šä¹‰ ---

def router_node(state: MultiAgentState):
    """è·¯ç”±èŠ‚ç‚¹"""
    question = state["messages"][-1].content
    print(f"\nğŸ§­ [è·¯ç”±] åˆ†æä»»åŠ¡: {question}")
    
    prompt = f"""
    åˆ†æç”¨æˆ·é—®é¢˜ï¼Œé€‰æ‹©å…³é”®è¯ï¼ˆç©ºæ ¼éš”å¼€ï¼‰ï¼š
    - TOOL (è®¡ç®—ç±»ï¼šBMIã€è¡€å‹ã€çƒ­é‡)
    - RAG (çŸ¥è¯†ç±»ï¼šç–¾ç—…ã€æ²»ç–—ã€åŸç†)
    - LIFESTYLE (å»ºè®®ç±»ï¼šé¥®é£Ÿã€è¿åŠ¨)
    
    é—®é¢˜ï¼š"{question}"
    """
    decision = llm.invoke(prompt).content.upper()
    print(f"  ğŸ‘‰ è§„åˆ’: {decision}")
    
    return {
        "need_tool": "TOOL" in decision,
        "need_rag": "RAG" in decision,
        "need_lifestyle": "LIFESTYLE" in decision,
        "loop_step": 0,
        "documents": [],
        "used_web_search": False # åˆå§‹åŒ–ä¸º False
    }

def tool_node(state: MultiAgentState):
    """å·¥å…·èŠ‚ç‚¹"""
    print("ğŸ”§ [å·¥å…·] æ­£åœ¨è®¡ç®—...")
    question = state["messages"][-1].content
    response = llm_with_tools.invoke(question)
    output = ""
    if response.tool_calls:
        results = []
        for call in response.tool_calls:
            tool = next((t for t in medical_tools_list if t.name == call["name"]), None)
            if tool:
                try:
                    res = tool.invoke(call["args"])
                    results.append(str(res))
                except Exception as e:
                    results.append(f"Error: {e}")
        output = "\n".join(results)
    return {"tool_output": output}

def retrieve_node(state: MultiAgentState):
    """æœ¬åœ°æ£€ç´¢èŠ‚ç‚¹"""
    print("ğŸ“š [æœ¬åœ°RAG] æ£€ç´¢çŸ¥è¯†åº“...")
    question = state["messages"][-1].content
    if state.get("tool_output"): question += f" {state['tool_output']}"

    # æœ¬åœ°æ£€ç´¢
    docs = vectorstore.similarity_search(question, k=4)
    doc_contents = [d.page_content for d in docs]
    
    return {"documents": doc_contents, "loop_step": state["loop_step"] + 1}

def web_search_node(state: MultiAgentState):
    """ğŸ”¥ æ–°å¢ï¼šWeb æœç´¢èŠ‚ç‚¹"""
    print("ğŸŒ [Webæœç´¢] æœ¬åœ°æ— ç»“æœï¼Œæ­£åœ¨è”ç½‘æœç´¢...")
    question = state["messages"][-1].content
    
    try:
        # ä½¿ç”¨ Tavily æœç´¢
        results = web_search_tool.invoke({"query": question})
        # æå–å†…å®¹ (Tavily è¿”å›çš„æ˜¯ list[dict])
        web_contents = [res['content'] for res in results]
        print(f"    âœ… è”ç½‘è·å–äº† {len(web_contents)} æ¡ç»“æœ")
        return {"documents": web_contents, "used_web_search": True}
    except Exception as e:
        print(f"    âŒ è”ç½‘æœç´¢å¤±è´¥: {e}")
        return {"documents": ["ç½‘ç»œæœç´¢å¤±è´¥ï¼Œè¯·ç¨åé‡è¯•ã€‚"], "used_web_search": True}

def grade_and_generate_node(state: MultiAgentState):
    """è¯„åˆ†ä¸ç”Ÿæˆå†³ç­–èŠ‚ç‚¹"""
    question = state["messages"][-1].content
    docs = state["documents"]
    
    # 1. è¯„åˆ†
    score = grade_documents(question, docs)
    
    # 2. å†³ç­–é€»è¾‘
    if score == "yes":
        # A. èµ„æ–™ç›¸å…³ -> ç›´æ¥ç”Ÿæˆ
        print("ğŸ’¡ [ç”Ÿæˆ] èµ„æ–™ç›¸å…³ï¼Œç”Ÿæˆå›ç­”...")
        context = "\n\n".join(docs)
        # æ ‡æ³¨æ¥æº
        source_tag = "(æ¥æº: äº’è”ç½‘)" if state["used_web_search"] else "(æ¥æº: æœ¬åœ°çŸ¥è¯†åº“)"
        prompt = f"åŸºäºèµ„æ–™å›ç­”({source_tag})ï¼š\nèµ„æ–™ï¼š{context}\né—®é¢˜ï¼š{question}"
        answer = llm.invoke(prompt).content
        return {"rag_output": answer, "final_answer": "ready"}
        
    elif state["loop_step"] >= 3:
        # B. é‡è¯•æ¬¡æ•°è¶…é™
        if not state["used_web_search"]:
            # -> è¿˜æ²¡è”ç½‘è¿‡ -> æŒ‡ç¤ºè·¯ç”±å»è”ç½‘
            print("  âš ï¸ æœ¬åœ°å¤šæ¬¡é‡è¯•å¤±è´¥ï¼Œè½¬å…¥ Web æœç´¢...")
            return {"final_answer": "go_web"}
        else:
            # -> è”ç½‘äº†è¿˜æ˜¯ä¸è¡Œ -> å¼ºè¡Œå›ç­”
            print("  âš ï¸ è”ç½‘ä¹Ÿæœä¸åˆ°ï¼Œå¼ºè¡Œå›ç­”ã€‚")
            context = "\n\n".join(docs)
            prompt = f"èµ„æ–™ç›¸å…³æ€§ä½ï¼Œè¯·å°½åŠ›å›ç­”ï¼š\nèµ„æ–™ï¼š{context}\né—®é¢˜ï¼š{question}"
            answer = llm.invoke(prompt).content
            return {"rag_output": answer, "final_answer": "ready"}
            
    else:
        # C. ä¸ç›¸å…³ä¸”æ²¡è¶…é™ -> é‡å†™é—®é¢˜
        new_query = rewrite_query(question)
        return {"messages": [HumanMessage(content=new_query)]}

def lifestyle_node(state: MultiAgentState):
    """ç”Ÿæ´»å»ºè®®èŠ‚ç‚¹"""
    print("ğŸƒ [ç”Ÿæ´»] ç”Ÿæˆå»ºè®®...")
    question = state["messages"][-1].content
    context = search_knowledge_base(f"å»ºè®® {question}", k=4)
    prompt = f"æä¾›ç”Ÿæ´»å»ºè®®ï¼š\nèµ„æ–™ï¼š{context}\né—®é¢˜ï¼š{question}"
    advice = llm.invoke(prompt).content
    return {"lifestyle_output": advice}

def summarizer_node(state: MultiAgentState):
    """æ€»ç»“èŠ‚ç‚¹"""
    print("ğŸ“Š [æ€»ç»“] æ•´åˆè¾“å‡º...")
    parts = []
    if state.get("tool_output"): parts.append(f"ğŸ“‹ ã€å¥åº·è¯„ä¼°ã€‘\n{state['tool_output']}")
    if state.get("rag_output"): parts.append(f"ğŸ“– ã€åŒ»å­¦çŸ¥è¯†ã€‘\n{state['rag_output']}")
    if state.get("lifestyle_output"): parts.append(f"ğŸ’¡ ã€ç”Ÿæ´»å»ºè®®ã€‘\n{state['lifestyle_output']}")
    
    final_text = "\n\n" + "="*30 + "\n\n".join(parts) if parts else "æŠ±æ­‰ï¼Œæ— æ³•å›ç­”ã€‚"
    return {"final_answer": final_text, "messages": [AIMessage(content=final_text)]}

# --- 4. æ„å»ºå›¾é€»è¾‘ ---
workflow = StateGraph(MultiAgentState)

workflow.add_node("router", router_node)
workflow.add_node("tool_agent", tool_node)
workflow.add_node("lifestyle_agent", lifestyle_node)
workflow.add_node("summarizer", summarizer_node)

# Self-RAG + Web èŠ‚ç‚¹
workflow.add_node("retrieve", retrieve_node)
workflow.add_node("grade_loop", grade_and_generate_node)
workflow.add_node("web_search", web_search_node) # ğŸ”¥ æ–°å¢èŠ‚ç‚¹

workflow.add_edge(START, "router")

def route_after_router(state):
    if state["need_tool"]: return "tool_agent"
    if state["need_rag"]: return "retrieve"
    if state["need_lifestyle"]: return "lifestyle_agent"
    return "summarizer"

workflow.add_conditional_edges("router", route_after_router)
workflow.add_conditional_edges("tool_agent", lambda x: "retrieve" if x["need_rag"] else ("lifestyle_agent" if x["need_lifestyle"] else "summarizer"))

# æ ¸å¿ƒï¼šæœ¬åœ°æ£€ç´¢ -> è¯„åˆ†/ç”Ÿæˆ
workflow.add_edge("retrieve", "grade_loop")

# ğŸ”¥ æ ¸å¿ƒè·¯ç”±é€»è¾‘æ›´æ–°ï¼šå¤„ç† Web æœç´¢è·³è½¬
def route_self_rag(state):
    decision = state.get("final_answer")
    
    if decision == "ready":
        # å®Œæˆ RAGï¼Œçœ‹æ˜¯å¦éœ€è¦ç”Ÿæ´»å»ºè®®
        return "lifestyle_agent" if state["need_lifestyle"] else "summarizer"
    elif decision == "go_web":
        # æœ¬åœ°æœä¸åˆ° -> å»è”ç½‘
        return "web_search"
    else:
        # ç»§ç»­æœ¬åœ°é‡è¯• (Rewrite loop)
        return "retrieve"

workflow.add_conditional_edges("grade_loop", route_self_rag, 
    {"lifestyle_agent": "lifestyle_agent", "summarizer": "summarizer", "retrieve": "retrieve", "web_search": "web_search"}
)

# è”ç½‘æœç´¢åï¼Œå†æ¬¡å»è¯„åˆ†å’Œç”Ÿæˆ (ç»™å®ƒä¸€æ¬¡æœºä¼šåˆ¤æ–­ç½‘ä¸Šçš„å†…å®¹å¯¹ä¸å¯¹)
workflow.add_edge("web_search", "grade_loop")

workflow.add_edge("lifestyle_agent", "summarizer")
workflow.add_edge("summarizer", END)

# --- 5. è¿è¡Œ ---
conn = sqlite3.connect("chat_history.db", check_same_thread=False)
memory = SqliteSaver(conn)
app = workflow.compile(checkpointer=memory)

if __name__ == "__main__":
    print("="*50)
    print("ğŸš€ Self-RAG + Web Search (å…¨èƒ½åŒ»å­¦åŠ©æ‰‹)")
    if not os.environ.get("TAVILY_API_KEY"):
        print("âš ï¸ è­¦å‘Š: æœªæ£€æµ‹åˆ° TAVILY_API_KEYï¼Œè”ç½‘æœç´¢å¯èƒ½å¤±è´¥ï¼")
    print("="*50)
    
    user_id = input("Session ID (Enter for new): ").strip()
    thread_id = user_id if user_id else str(uuid.uuid4())
    print(f"âœ¨ Session: {thread_id}")
    
    while True:
        try:
            user_input = input("\nğŸ‘¤ æ‚£è€…: ").strip()
            if user_input.lower() in ["q", "quit"]: break
            if user_input == "/new": thread_id = str(uuid.uuid4()); print("âœ¨ New Session"); continue
            if not user_input: continue

            config = {"configurable": {"thread_id": thread_id}}
            
            # æ•è·æœ€ç»ˆç»“æœ
            final_res = None
            for event in app.stream({"messages": [HumanMessage(content=user_input)]}, config):
                if "summarizer" in event:
                    final_res = event["summarizer"]["final_answer"]
            
            if final_res:
                print(final_res)
            
        except KeyboardInterrupt: break
        except Exception as e: print(f"âŒ Error: {e}")