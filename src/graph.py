import operator
from typing import Annotated, TypedDict, Union
from langchain_ollama import ChatOllama
from langchain_core.messages import SystemMessage, HumanMessage, AIMessage, BaseMessage
from langgraph.graph import StateGraph, START, END
from langgraph.graph.message import add_messages

# --- 1. å®šä¹‰çŠ¶æ€ (State) ---
# è¿™æ˜¯ Agent çš„"çŸ­æœŸè®°å¿†"ã€‚å®ƒä¼šä¿å­˜å¯¹è¯å†å²ï¼Œä¾›æ‰€æœ‰èŠ‚ç‚¹è¯»å–ã€‚
class AgentState(TypedDict):
    # add_messages æ˜¯ LangGraph çš„é­”æ³•ï¼Œå®ƒä¼šè‡ªåŠ¨æŠŠæ–°æ¶ˆæ¯è¿½åŠ åˆ°åˆ—è¡¨é‡Œï¼Œè€Œä¸æ˜¯è¦†ç›–
    messages: Annotated[list[BaseMessage], add_messages]

# --- 2. åˆå§‹åŒ–æ¨¡å‹ (Engine) ---
# è¿æ¥ä½ é‚£å° OMEN 8 Pro ä¸Šçš„ Ollama
llm = ChatOllama(
    model="qwen2.5:7b",
    temperature=0,  # åŒ»ç–—åœºæ™¯è®¾ä¸º 0ï¼Œè®©å®ƒä¸¥è°¨ç‚¹ï¼Œåˆ«çç¼–
)

# --- 3. å®šä¹‰èŠ‚ç‚¹ (Nodes) ---
# èŠ‚ç‚¹å°±æ˜¯"å¹²æ´»çš„äºº"ã€‚ç›®å‰æˆ‘ä»¬åªæœ‰ä¸€ä¸ªå…¨èƒ½èŠ‚ç‚¹ï¼šchatbot

def chatbot_node(state: AgentState):
    """
    è¿™æ˜¯æœ€åŸºç¡€çš„å¯¹è¯èŠ‚ç‚¹ã€‚
    å®ƒæ¥æ”¶å½“å‰çš„çŠ¶æ€ï¼ˆstateï¼‰ï¼Œè°ƒç”¨å¤§æ¨¡å‹ï¼Œç„¶åè¿”å›ç”Ÿæˆçš„å›ç­”ã€‚
    """
    # è·å–å†å²æ¶ˆæ¯
    messages = state["messages"]
    
    # è°ƒç”¨ Qwen2.5
    response = llm.invoke(messages)
    
    # è¿”å›ç»“æœï¼ŒLangGraph ä¼šè‡ªåŠ¨æŠŠå®ƒåŠ åˆ° state["messages"] é‡Œ
    return {"messages": [response]}

# --- 4. æ„å»ºå›¾ (Build the Graph) ---
# è¿™æ˜¯ Agent çš„"æŒ‡æŒ¥ä¸­å¿ƒ"

workflow = StateGraph(AgentState)

# æ·»åŠ èŠ‚ç‚¹
workflow.add_node("chatbot", chatbot_node)

# æ·»åŠ è¾¹ (Edges)
# é€»è¾‘ï¼šå¼€å§‹ -> èŠå¤© -> ç»“æŸ
# ä»¥åæˆ‘ä»¬ä¼šåœ¨è¿™é‡ŒåŠ ï¼šå¼€å§‹ -> æ£€ç´¢(RAG) -> æ£€æŸ¥(Safety) -> èŠå¤©
workflow.add_edge(START, "chatbot")
workflow.add_edge("chatbot", END)

# ç¼–è¯‘å›¾ (Compile)
# è¿™ä¸€æ­¥ä¼šæŠŠä½ çš„é€»è¾‘å˜æˆä¸€ä¸ªå¯æ‰§è¡Œçš„ç¨‹åº
app = workflow.compile()

# --- 5. æœ¬åœ°æµ‹è¯•ä»£ç  ---
if __name__ == "__main__":
    print("ğŸ¥ SafeMed-Agent æ ¸å¿ƒå¼•æ“å·²å¯åŠ¨ (æŒ‰ 'q' é€€å‡º)...")
    
    # ç»™å®ƒæ³¨å…¥ä¸€ä¸ªâ€œäººè®¾â€ï¼Œè®©å®ƒçŸ¥é“è‡ªå·±æ˜¯åŒ»ç–—åŠ©æ‰‹
    sys_msg = SystemMessage(content="ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„åŒ»ç–—AIåŠ©æ‰‹ã€‚è¯·ç”¨ä¸­æ–‡å›ç­”ï¼Œä¿æŒä¸¥è°¨ã€‚")
    
    # æ¨¡æ‹Ÿç®€å•çš„ç»ˆç«¯å¯¹è¯
    while True:
        user_input = input("\næ‚£è€…(ä½ ): ")
        if user_input.lower() in ["q", "quit", "exit"]:
            print("å†è§ï¼")
            break
            
        # è¿è¡Œå›¾
        # config={"configurable": {"thread_id": "1"}} ä»¥åç”¨äºæŒä¹…åŒ–è®°å¿†
        inputs = {"messages": [sys_msg, HumanMessage(content=user_input)]}
        
        # stream æ–¹æ³•è®©å­—ä¸€ä¸ªä¸€ä¸ªè¹¦å‡ºæ¥ï¼Œçœ‹ç€æ›´çˆ½
        for event in app.stream(inputs):
            for value in event.values():
                print(f"Agent(Qwen): {value['messages'][-1].content}")