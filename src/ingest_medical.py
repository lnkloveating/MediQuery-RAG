import re
import os
from langchain_ollama import OllamaEmbeddings
from langchain_chroma import Chroma
from langchain_core.documents import Document

# 1. é…ç½®
DATA_FILE = "RAGè¶…è¶Šç™¾å²(åŸä¹¦)20250506.docx" 
DB_PATH = "./medical_db"

def parse_custom_format(file_path):
    """
    è§£æç‰¹å®šæ ¼å¼çš„åŒ»ç–—æ•°æ®æ–‡ä»¶
    """
    if not os.path.exists(file_path):
        print(f"âŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ°æ–‡ä»¶ {file_path}")
        return []
    
    with open(file_path, 'r', encoding='utf-8') as f:
        text = f.read()

    # --- åˆ†å‰²é€»è¾‘ ---
    # ä½¿ç”¨ chunk_id ä½œä¸ºåˆ†å‰²ç¬¦
    chunks = re.split(r'chunk_id:', text)
    
    documents = []
    
    # è·³è¿‡ç¬¬ä¸€ä¸ªç©ºçš„
    for chunk in chunks:
        if not chunk.strip(): continue
        
        try:
            # --- æå– Title ---
            title_match = re.search(r'title:\s*(.*?)\n', chunk)
            title = title_match.group(1).strip() if title_match else "æœªå‘½å"
            
            # --- æå– Content (æ ¸å¿ƒä¿®å¤éƒ¨åˆ†) ---
            content = ""
            content_match = re.search(r'content:\s*', chunk)
            
            if content_match:
                start_index = content_match.end()
                
                # å°è¯•æ‰¾ content åé¢ç´§è·Ÿçš„ "source:" æ ‡ç­¾ä½œä¸ºç»“æŸç‚¹
                end_index = chunk.find('source:', start_index)
                
                # å¦‚æœæ²¡æ‰¾åˆ° sourceï¼Œè¯•ç€æ‰¾ tags
                if end_index == -1:
                    end_index = chunk.find('tags:', start_index)
                
                if end_index != -1:
                    # æˆªå–ä¸­é—´çš„å†…å®¹
                    raw_content = chunk[start_index:end_index]
                    
                    # ã€é€»è¾‘ä¿®å¤ã€‘æ£€æŸ¥å†…å®¹é‡Œæ˜¯å¦æ··å…¥äº†æ ‡ç­¾ï¼Œå¦‚æœæœ‰ï¼Œåˆ‡æ‰å®ƒ
                    if "source:" in raw_content or "tags:" in raw_content:
                        # å¦‚æœå†…å®¹é‡Œæ··å…¥äº†æ ‡ç­¾ï¼Œåœ¨ç¬¬ä¸€ä¸ªæ ‡ç­¾å¤„åˆ‡æ–­
                        raw_content = raw_content.split('source:')[0].split('tags:')[0]
                    
                    content = raw_content.strip()
                else:
                    # å¦‚æœåé¢æ²¡æ ‡ç­¾äº†ï¼Œå°±å–åˆ°æœ€å
                    content = chunk[start_index:].strip()

            # --- æå– Tags ---
            tags_match = re.search(r'tags:\s*(.*?)\n', chunk)
            tags = tags_match.group(1).strip() if tags_match else ""

            # --- ç»„è£… Document ---
            if title or content:
                full_text = f"é—®é¢˜ï¼š{title}\nç­”æ¡ˆï¼š{content}"
                
                doc = Document(
                    page_content=full_text,
                    metadata={
                        "title": title,
                        "tags": tags,
                        "source": "ã€Šè¶…è¶Šç™¾å²ã€‹"
                    }
                )
                documents.append(doc)
            
        except Exception as e:
            print(f"âš ï¸ è§£æè·³è¿‡ä¸€ä¸ªå—ï¼ŒåŸå› : {e}")
            continue

    return documents

# 2. æ‰§è¡Œå…¥åº“
if __name__ == "__main__":
    # âš ï¸ è¯·ç¡®è®¤è¿™é‡Œçš„æ–‡ä»¶è·¯å¾„æ˜¯å¦æ­£ç¡®
    # å¦‚æœä½ çš„ txt æ–‡ä»¶åœ¨ data æ–‡ä»¶å¤¹ä¸‹ï¼Œè¯·ä¿æŒä¸å˜
    txt_path = "./data/medical_data.txt" 
    
    print(f"ğŸ“‚ å‡†å¤‡è¯»å–æ–‡ä»¶: {txt_path}")
    
    docs = parse_custom_format(txt_path)
    
    if len(docs) > 0:
        print(f"ğŸ§¹ è§£ææˆåŠŸï¼å…±æ¸…æ´—å‡º {len(docs)} ä¸ªçŸ¥è¯†å—ã€‚")
        print(f"ğŸ‘€ é¢„è§ˆç¬¬ä¸€æ¡æ•°æ®ï¼š\nTitle: {docs[0].metadata['title']}\nContentç‰‡æ®µ: {docs[0].page_content[:50]}...")
        
        print("\nğŸ’‰ æ­£åœ¨æ³¨å…¥å‘é‡æ•°æ®åº“ (Chroma)...")
        embeddings = OllamaEmbeddings(model="shaw/dmeta-embedding-zh")
        
        vectorstore = Chroma.from_documents(
            documents=docs,
            embedding=embeddings,
            persist_directory=DB_PATH
        )
        print("ğŸš€ æ•°æ®åº“æ„å»ºå®Œæˆï¼")
    else:
        print("âš ï¸ æœªæå–åˆ°ä»»ä½•æ•°æ®ï¼Œè¯·æ£€æŸ¥ txt_path è·¯å¾„æ˜¯å¦æ­£ç¡®ã€‚")